{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "949jxQlGF1En"
      },
      "source": [
        "# **K Nearest Neighbors: 50 Points**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZWlFYBRF1En"
      },
      "source": [
        "K-Nearest Neighbors (KNN) is a supervised learning algorithm used for both classification and regression tasks. It doesn't learn parameters or rules like other methods, but instead predicts outputs based on the similarity of inputs. In classification, a new instance is assigned the most common class among its 'K' closest instances from the training data. In regression, it's assigned the average value of the 'K' nearest instances. The choice of 'K' and proper scaling of input features are crucial for optimal results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zm9Y3Cq3F1En"
      },
      "source": [
        "**Importing all the required libraries.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yirfjNb9F1Eo"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Dataset**"
      ],
      "metadata": {
        "id": "YtKQvs9niurN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to be using the wine toy dataset from SciKit Learn"
      ],
      "metadata": {
        "id": "T92FPNbHi_BX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "wine_data = load_wine()"
      ],
      "metadata": {
        "id": "f9bNpHrOiqEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrNrFJWjF1Eo"
      },
      "source": [
        "**Data Processing**\n",
        "\n",
        "**TODO: Split the Dataset (5 Points)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lZCcOaSF1Eo"
      },
      "outputs": [],
      "source": [
        "def data_processing(wine_data):\n",
        "    # Split the dataset into training set and temporary set using 80-20 split, use random_state = 0\n",
        "    ##### INPUT CODE HERE (~1 line of code) ######\n",
        "\n",
        "    ##############################################\n",
        "\n",
        "    # Split the temporary set into validation set and test set using 50-50 split, use random_state = 0\n",
        "    ##### INPUT CODE HERE (~1 line of code) ######\n",
        "\n",
        "    ##############################################\n",
        "    \n",
        "\n",
        "    # Convert all datasets into numpy arrays\n",
        "    X_train = np.array(X_train)\n",
        "    X_val = np.array(X_val)\n",
        "    X_test = np.array(X_test)\n",
        "\n",
        "    y_train = np.array(y_train)\n",
        "    y_val = np.array(y_val)\n",
        "    y_test = np.array(y_test)\n",
        "\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gT_mV5ZmF1Eo"
      },
      "source": [
        "**Data Processing With Transformations (MinMax and Normalization)**  \n",
        "**TODO: Add MinMax and Normalization Code (5 Points)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36z1oLEGF1Ep"
      },
      "outputs": [],
      "source": [
        "def data_processing_with_transformation(wine_data, do_minmax_scaling=True, do_normalization=False):\n",
        "    # Split the dataset into training set and temporary set using 80-20 split, use random_state = 0\n",
        "    ##### INPUT CODE HERE (~1 line of code) ######\n",
        "\n",
        "    ##############################################\n",
        "    \n",
        "\n",
        "    # Split the temporary set into validation set and test set using 50-50 split, use random_state = 0\n",
        "    ##### INPUT CODE HERE (~1 line of code) ######\n",
        "\n",
        "    ##############################################\n",
        "    \n",
        "\n",
        "    # Convert all datasets into numpy arrays\n",
        "    X_train = np.array(X_train)\n",
        "    X_val = np.array(X_val)\n",
        "    X_test = np.array(X_test)\n",
        "\n",
        "    y_train = np.array(y_train)\n",
        "    y_val = np.array(y_val)\n",
        "    y_test = np.array(y_test)\n",
        "\n",
        "    # Min-Max scaling\n",
        "    if do_minmax_scaling:\n",
        "        #####################################################\n",
        "        #             YOUR CODE HERE                        #\n",
        "        #####################################################\n",
        "\n",
        "    # Normalization\n",
        "    if do_normalization:\n",
        "        #####################################################\n",
        "        #             YOUR CODE HERE                        #\n",
        "        #####################################################\n",
        "\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCmRfvqDF1Ep"
      },
      "source": [
        "**TODO: Complete compute_l2_distances( ) function  (10 Points)**\n",
        "\n",
        "The L2 distance, also known as the Euclidean distance, is a measure of the straight line distance between two points in a space. It is commonly used in machine learning to compute the similarity between vectors.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ONIdMBrF1Ep"
      },
      "source": [
        "The L2 distance, or Euclidean distance, between two vectors `x` and `x'` is given by:\n",
        "\n",
        "$$\n",
        "d(x, x') = \\left\\| x - x' \\right\\|_2 = \\sqrt{\\sum_{i} (x_i - x'_i)^2}\n",
        "$$\n",
        "\n",
        "Where:\n",
        "\n",
        "- $d(x, x')$ is the L2 distance between vectors `x` and `x'`\n",
        "- $x_i$ is the ith element of vector `x`\n",
        "- $x'_i$ is the ith element of vector `x'`\n",
        "- The sum is over all elements of the vectors\n",
        "\n",
        "The square root of the sum of the squared differences of the corresponding elements of the vectors gives the L2 distance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfCrUP0SF1Ep"
      },
      "outputs": [],
      "source": [
        "def compute_l2_distances(Xtrain, X):\n",
        "    \"\"\"\n",
        "    Compute the distance between each test point in X and each training point\n",
        "    in Xtrain.\n",
        "    Inputs:\n",
        "    - Xtrain: A numpy array of shape (num_train, D) containing training data\n",
        "    - X: A numpy array of shape (num_test, D) containing test data.\n",
        "    Returns:\n",
        "    - dists: A numpy array of shape (num_test, num_train) where dists[i, j]\n",
        "      is the Euclidean distance between the ith test point and the jth training\n",
        "      point.\n",
        "    \"\"\"\n",
        "    #####################################################\n",
        "    #             YOUR CODE HERE                        #\n",
        "    #####################################################\n",
        "    return dists"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeuRWM4NF1Eq"
      },
      "source": [
        ":**TODO: Complete compute_cosine_distances( ) function  (10 Points)**\n",
        "\n",
        "Cosine distance is a measure of dissimilarity between two vectors that goes from 0 to 2. It is derived from the cosine similarity measure, which calculates the cosine of the angle between two vectors.\n",
        "\n",
        "The cosine distance between two vectors `x` and `x'` is given by:\n",
        "\n",
        "$$\n",
        "d(x, x') = \n",
        "\\begin{cases} \n",
        "1 & \\text{if } \\|x\\|_2 = 0 \\text{ or } \\|x'\\|_2 = 0 \\\\\n",
        "1 - \\frac{x \\cdot x'}{\\|x\\|_2 \\|x'\\|_2} & \\text{otherwise}\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "Where:\n",
        "\n",
        "- $d(x, x')$ is the cosine distance between vectors `x` and `x'`\n",
        "- $x \\cdot x'$ is the dot product of vectors `x` and `x'`\n",
        "- $\\|x\\|_2$ and $\\|x'\\|_2$ are the L2 norms (or magnitudes) of the vectors `x` and `x'`\n",
        "- The condition checks if either norm is zero. If so, it returns 1, otherwise it calculates the cosine distance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwN3Dl6QF1Eq"
      },
      "outputs": [],
      "source": [
        "def compute_cosine_distances(Xtrain, X):\n",
        "    \"\"\"\n",
        "    Compute the distance between each test point in X and each training point\n",
        "    in Xtrain.\n",
        "    Inputs:\n",
        "    - Xtrain: A numpy array of shape (num_train, D) containing training data\n",
        "    - X: A numpy array of shape (num_test, D) containing test data.\n",
        "    Returns:\n",
        "    - dists: A numpy array of shape (num_test, num_train) where dists[i, j]\n",
        "      is the Cosine distance between the ith test point and the jth training\n",
        "      point.\n",
        "    \"\"\"\n",
        "    #####################################################\n",
        "    #             YOUR CODE HERE                        #\n",
        "    #####################################################\n",
        "    return dists"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIEO1bCOF1Eq"
      },
      "source": [
        "**TODO: Complete predict_labels( ) function (5 Points)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pf6-NFfiF1Er"
      },
      "outputs": [],
      "source": [
        "def predict_labels(k, ytrain, dists):\n",
        "    \"\"\"\n",
        "    Given a matrix of distances between test points and training points,\n",
        "    predict a label for each test point.\n",
        "    Inputs:\n",
        "    - k: The number of nearest neighbors used for prediction.\n",
        "    - ytrain: A numpy array of shape (num_train,) where ytrain[i] is the label\n",
        "      of the ith training point.\n",
        "    - dists: A numpy array of shape (num_test, num_train) where dists[i, j]\n",
        "      gives the distance betwen the ith test point and the jth training point.\n",
        "    Returns:\n",
        "    - ypred: A numpy array of shape (num_test,) containing predicted labels for the\n",
        "      test data, where y[i] is the predicted label for the test point X[i].\n",
        "    \"\"\"\n",
        "    #####################################################\n",
        "    #             YOUR CODE HERE                        #\n",
        "    #####################################################\n",
        "    return ypred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9Zk8w6gF1Er"
      },
      "source": [
        "**TODO: Complete compute_error_rate( ) function (5 Points)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSmILXe3F1Er"
      },
      "outputs": [],
      "source": [
        "def compute_error_rate(y, ypred):\n",
        "    \"\"\"\n",
        "    Compute the error rate of prediction based on the true labels.\n",
        "    Inputs:\n",
        "    - y: A numpy array with of shape (num_test,) where y[i] is the true label\n",
        "      of the ith test point.\n",
        "    - ypred: A numpy array with of shape (num_test,) where ypred[i] is the\n",
        "      prediction of the ith test point.\n",
        "    Returns:\n",
        "    - err: The error rate of prediction (scalar).\n",
        "    \"\"\"\n",
        "    #####################################################\n",
        "    #             YOUR CODE HERE                        #\n",
        "    #####################################################\n",
        "    return err"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1LODccXF1Er"
      },
      "source": [
        "**TODO: Complete find_best_k( ) function (10 Points)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b5UIrpmF1Es"
      },
      "outputs": [],
      "source": [
        "def find_best_k(K, ytrain, dists, yval):\n",
        "    \"\"\"\n",
        "    Find best k according to validation error rate.\n",
        "    Inputs:\n",
        "    - K: A list of ks.\n",
        "    - ytrain: A numpy array of shape (num_train,) where ytrain[i] is the label\n",
        "      of the ith training point.\n",
        "    - dists: A numpy array of shape (num_test, num_train) where dists[i, j]\n",
        "      is the distance between the ith test point and the jth training\n",
        "      point.\n",
        "    - yval: A numpy array with of shape (num_val,) where y[i] is the true label\n",
        "      of the ith validation point.**TODO**: Complete compute_l2_distances( ) function\n",
        "    Returns:\n",
        "    - best_k: The k with the lowest error rate.\n",
        "    - validation_error: A list of error rate of different ks in K.\n",
        "    - best_err: The lowest error rate we get from all ks in K.\n",
        "    \"\"\"\n",
        "    #####################################################\n",
        "    #             YOUR CODE HERE                        #\n",
        "    #####################################################\n",
        "    return best_k, validation_error, best_err"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYBT086kF1Es"
      },
      "source": [
        "### Report 4-nearest neighbor accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fBik889F1Es"
      },
      "source": [
        "**Task**: Fill in the code for the function compute l2 distances .  \n",
        "**Task**: Fill in the code for the function predict labels ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nvum-R5-F1Es"
      },
      "source": [
        "**Report Item**: Report the error rate of your k nearest neighbor algorithm in the validation set when k = 4 using\n",
        "Euclidean distance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dnior7X2F1Et"
      },
      "outputs": [],
      "source": [
        "#==================Problem Set 1.1=======================\n",
        "data = load_wine()\n",
        "output_file = 'knn_output.txt'\n",
        "# Compute distance matrix\n",
        "Xtrain, ytrain, Xval, yval, Xtest, ytest = data_processing(data)\n",
        "\n",
        "dists = compute_l2_distances(Xtrain, Xval)\n",
        "\n",
        "# Compute validation accuracy when k=4\n",
        "k = 4\n",
        "ypred = predict_labels(k, ytrain, dists)\n",
        "err = compute_error_rate(yval, ypred)\n",
        "print(\"The validation error rate is\", err, \"in Problem Set 1.1\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTb9DnFXF1Et"
      },
      "source": [
        "###  Data transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15ktl5EnF1Et"
      },
      "source": [
        "**Task**: Fill in the code for the function data processing with transformation ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVOTHW4KF1Et"
      },
      "source": [
        "**Report Item**: Report the error rate of your k nearest neighbor algorithm in the validation set for k = 4 using Euclidean distance when data is using (1) Normalized featured vector, and (2) Min-max scaling featured vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTSHk_7YF1Et"
      },
      "outputs": [],
      "source": [
        "#==================Problem Set 1.2=======================\n",
        "\n",
        "# Compute distance matrix\n",
        "Xtrain, ytrain, Xval, yval, Xtest, ytest = data_processing_with_transformation(data, do_minmax_scaling=False, do_normalization=True)\n",
        "\n",
        "dists = compute_l2_distances(Xtrain, Xval)\n",
        "\n",
        "# Compute validation accuracy when k=4\n",
        "k = 4\n",
        "ypred = predict_labels(k, ytrain, dists)\n",
        "err = compute_error_rate(yval, ypred)\n",
        "print(\"The validation error rate is\", err, \"in Problem Set 1.2 when using normalization\")\n",
        "print()\n",
        "\n",
        "# Compute distance matrix\n",
        "Xtrain, ytrain, Xval, yval, Xtest, ytest = data_processing_with_transformation(data, do_minmax_scaling=True, do_normalization=False)\n",
        "\n",
        "dists = compute_l2_distances(Xtrain, Xval)\n",
        "\n",
        "# Compute validation accuracy when k=4\n",
        "k = 4\n",
        "ypred = predict_labels(k, ytrain, dists)\n",
        "err = compute_error_rate(yval, ypred)\n",
        "print(\"The validation error rate is\", err, \"in Problem Set 1.2 when using minmax_scaling\")\n",
        "print()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTk5N5aTF1Eu"
      },
      "source": [
        "### Different distance measurement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kPNJAP1F1Eu"
      },
      "source": [
        "**Task**: Fill in the code for the function compute cosine distances and change distance function used in the main func- tion in the code to get results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaQQNc-tF1Eu"
      },
      "source": [
        "**Report Item**: Report the error rate of your k nearest neighbor algorithm in the validation set for k = 4 using cosine distance for original data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XToosrIoF1Eu"
      },
      "outputs": [],
      "source": [
        "#==================Problem Set 1.3=======================\n",
        "\n",
        "# Compute distance matrix\n",
        "Xtrain, ytrain, Xval, yval, Xtest, ytest = data_processing(data)\n",
        "dists = compute_cosine_distances(Xtrain, Xval)\n",
        "\n",
        "# Compute validation accuracy when k=4\n",
        "k = 4\n",
        "ypred = predict_labels(k, ytrain, dists)\n",
        "err = compute_error_rate(yval, ypred)\n",
        "print(\"The validation error rate is\", err, \"in Problem Set 1.3, which use cosine distance\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmaQkBstF1Ev"
      },
      "source": [
        "### Tuning the hyper-parameter k "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLqTJ83xF1Ev"
      },
      "source": [
        "**Task**: Fill in the code for the function find best k ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xH2mL9yMF1Ev"
      },
      "source": [
        "**Report Item**: \n",
        "1. Report and draw a curve based on the error rate of your model on the training set for each k. What do you observe?\n",
        "2. Report and draw a curve based on the error rate of your model on the validation set for each k. What is your best k?   \n",
        "3. What do you observe by comparing the difference between the two curves?\n",
        "4. What’s the final test set error rate you get using your best-k? \n",
        "5. Comment on these results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DLsGWGUF1Ev"
      },
      "outputs": [],
      "source": [
        "\n",
        "#==================Problem Set 1.4=======================\n",
        "# Compute distance matrix\n",
        "Xtrain, ytrain, Xval, yval, Xtest, ytest = data_processing(data)\n",
        "\n",
        "#======performance of different k in training set=====\n",
        "K = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n",
        "\n",
        "dists = compute_l2_distances(Xtrain, Xtrain)\n",
        "best_k, training_error, best_err = find_best_k(K, ytrain, dists, ytrain)\n",
        "\n",
        "#==========select the best k by using validation set==============\n",
        "dists = compute_l2_distances(Xtrain, Xval)\n",
        "best_k, validation_error, best_err = find_best_k(K, ytrain, dists, yval)\n",
        "\n",
        "#===============test the performance with your best k=============\n",
        "dists = compute_l2_distances(Xtrain, Xtest)\n",
        "ypred = predict_labels(best_k, ytrain, dists)\n",
        "test_err = compute_error_rate(ytest, ypred)\n",
        "print(\"In Problem Set 1.4, we use the best k = \", best_k, \"with the best validation error rate\", best_err)\n",
        "print(\"Using the best k, the final test error rate is\", test_err)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nYpTRU_F1Ew"
      },
      "outputs": [],
      "source": [
        "#====================write your results to file===================\n",
        "f=open(output_file, 'w')\n",
        "for i in range(len(K)):\n",
        "    f.write('%d %.3f' % (K[i], validation_error[i])+'\\n')\n",
        "f.write('%s %.3f' % ('test', test_err))\n",
        "f.close()\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.scatter(K, validation_error, color='red', label = 'Error Rates')\n",
        "plt.ylabel('Error', fontsize = 14)\n",
        "plt.xlabel('K Values', fontsize = 14)\n",
        "plt.title('K Values VS Error on Validation Set', fontsize = 18)\n",
        "plt.xticks(K)\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.savefig(\"Error_Rate_On_Validation_Set.png\")\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.scatter(K, training_error, color='red', label = 'Error Rates')\n",
        "plt.ylabel('Error', fontsize = 14)\n",
        "plt.xlabel('K Values', fontsize = 14)\n",
        "plt.title('K Values VS Error on Training Set', fontsize = 18)\n",
        "plt.xticks(K)\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.savefig(\"Error_Rate_On_Training_Set.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTorIDyxp9PA"
      },
      "source": [
        "# **Decision Tree Classification: 10 Points**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7UQXxqk_mIp"
      },
      "source": [
        "Decision Trees (DTs) are a non-parametric supervised learning method used for classification and regression. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features. A tree can be seen as a piecewise constant approximation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FmlIiAi__u1"
      },
      "source": [
        "**STEP 1: Importing all the required libraries.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CQFMu_co3uB"
      },
      "outputs": [],
      "source": [
        "# Libraries for data analysis\n",
        "import numpy as np # For large multi-dimensional array and matrix processing\n",
        "import pandas as pd # For data extraction and preparation\n",
        "\n",
        "#The sklearn.tree module includes decision tree-based models for classification and regression.\n",
        "from sklearn import tree\n",
        "\n",
        "# Libraries for displaying results and analysis\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tw2IL1zjARue"
      },
      "source": [
        "**STEP 2: Importing Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcZC7VWpAVde"
      },
      "source": [
        "We are going to be using the wine toy dataset from SciKit Learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZ8E5GxNteHV"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_wine\n",
        "wine_data = load_wine()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7H1o-aBUBNLC"
      },
      "source": [
        "You can optionally print the Description of the dataset for your reference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qn_6VEEHzNpd"
      },
      "outputs": [],
      "source": [
        "print(wine_data.data.shape)\n",
        "print(wine_data.target.shape)\n",
        "print(wine_data.DESCR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOK9ShfyBbD0"
      },
      "source": [
        "**STEP 3: Split the Dataset (2 Points)**\n",
        "\n",
        "**TO DO:** Similar to the KNN Tutorial, split the given X and y data into X_train, X_test, y_train, y_test, using **test ratio of 0.2 and random_state = 0**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bk8v4pJ5vVEn"
      },
      "outputs": [],
      "source": [
        "X = wine_data.data\n",
        "y = wine_data.target\n",
        "\n",
        "##### Use numpy arrays ######\n",
        "X_train = None\n",
        "y_train = None\n",
        "X_test = None\n",
        "y_test = None\n",
        "\n",
        "##### INPUT CODE HERE (~1 line of code) ######\n",
        "\n",
        "##############################################\n",
        "\n",
        "assert X_train.shape == (124,13)\n",
        "assert y_train.shape == (124,)\n",
        "assert X_test.shape == (54,13)\n",
        "assert y_test.shape == (54,)\n",
        "\n",
        "print(\"Size of training data= \", X_train.shape[0],\" Samples\")\n",
        "print(\"Size of testing data= \", X_test.shape[0],\" Samples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPip_B47Dza3"
      },
      "source": [
        "**STEP 4: Fit model to training data (2 Points)**\n",
        "\n",
        "**TO DO:** Create a Decision Tree object (named decision_tree) with random state 0 and max depth of 3. Fit the given decision tree to X_train and y_train data. You may use [this link](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.fit) for reference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrwrOMlj0Nkw"
      },
      "outputs": [],
      "source": [
        "decision_tree = None\n",
        "\n",
        "##### INPUT CODE HERE (~1 line of code) ######\n",
        "\n",
        "##############################################\n",
        "\n",
        "print(\"Simple Visualization of the tree you created:\")\n",
        "print(tree.export_text(decision_tree, feature_names=wine_data.feature_names))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmAT6f-qFSSF"
      },
      "source": [
        "**STEP 5: Testing the model (2 Points)**\n",
        "\n",
        "**TO DO:** Find target predictions by giving **X_test** input to your model and store them in **y_pred**. You may need [this link](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.predict) for reference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoXj0eqZDv-F"
      },
      "outputs": [],
      "source": [
        "y_pred = None\n",
        "\n",
        "##### INPUT CODE HERE (~1 line of code) ######\n",
        "\n",
        "##############################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ux7n7XZJF9VY"
      },
      "source": [
        "**STEP 6: Visualize the Results  (4 Points)**\n",
        "\n",
        "**TO DO:** Similar to the KNN Tutorial, plot confusion matrix, and accuracy of model predictions. Store accuracy in **acc** variable\n",
        "\n",
        "You may need the following references:\n",
        "\n",
        "[Confusion Matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)\n",
        "\n",
        "[Confusion Matrix Display](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html)\n",
        "\n",
        "[Accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSXyi0iYwuy6"
      },
      "outputs": [],
      "source": [
        "## Make sure to save your accuracy in the variable \"acc\"\n",
        "acc = 0\n",
        "##### INPUT CODE HERE (~4 line of code) ######\n",
        "# Make sure you plot the confusion matrix, i.e. once this code cell is run, it should output a 3X3 confusion matrix and accuracy #\n",
        "\n",
        "##############################################\n",
        "\n",
        "print('Accuracy of our model is equal to ' + str(round(acc, 2)) + ' %.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3YuUi8ZHY9f"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBbRybjU-xjE"
      },
      "source": [
        "# **Random Forest Regression: 15 Points**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGYwmGnGxn_u"
      },
      "source": [
        "Decision trees can also be applied to regression problems, using the DecisionTreeRegressor class.\n",
        "\n",
        "As in the classification setting, the fit method will take as argument arrays X and y, only that in this case y is expected to have floating point values instead of integer values:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48r-OKiExtSw"
      },
      "source": [
        "**STEP 1: Importing all the required libraries.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kE4RyoD-4-z"
      },
      "outputs": [],
      "source": [
        "#The sklearn.ensemble module includes the RandomForest algorithm.\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Libraries for calculating evaluation metrics\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "las8qWOUHfh2"
      },
      "source": [
        "**STEP 2: Importing Dataset**\n",
        "\n",
        "We are going to be using the California Housing dataset.\n",
        "It contains 20640 samples with 8 dimensions to predict the value of a house.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8NUIU9Z_YE4"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "housing_data = fetch_california_housing()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njTHiuTYyOiO"
      },
      "source": [
        "You can optionally print the description and a few samples from the dataset for your reference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YduDpy8BsWD"
      },
      "outputs": [],
      "source": [
        "print(housing_data.keys())\n",
        "print(housing_data.data.shape)\n",
        "print(housing_data.DESCR)\n",
        "\n",
        "print(pd.DataFrame(housing_data.data)[:5])\n",
        "print(pd.DataFrame(housing_data.target)[:5])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sspyXSmy17q"
      },
      "source": [
        "**STEP 3: Split the Dataset (3 Points)**\n",
        "\n",
        "**TO DO:** Similar to the KNN Tutorial, split the given X and y data into X_train, X_test, y_train, y_test, using **test ratio of 0.2 and a random state of 0**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlcuTTiTy9Tk"
      },
      "outputs": [],
      "source": [
        "from pandas.core.common import random_state\n",
        "X = housing_data.data\n",
        "y = housing_data.target\n",
        "\n",
        "\n",
        "##### Use numpy arrays ######\n",
        "X_train = None\n",
        "y_train = None\n",
        "X_test = None\n",
        "y_test = None\n",
        "\n",
        "\n",
        "##### INPUT CODE HERE (~1 line of code) ######\n",
        "\n",
        "##############################################\n",
        "\n",
        "assert X_train.shape == (14448, 8)\n",
        "assert y_train.shape == (14448,)\n",
        "assert X_test.shape == (6192, 8)\n",
        "assert y_test.shape == (6192,)\n",
        "\n",
        "print(\"Size of training data= \", X_train.shape[0],\" Samples\")\n",
        "print(\"Size of testing data= \", X_test.shape[0],\" Samples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3WOEAy8zjln"
      },
      "source": [
        "**STEP 4: Fit model to training data (4 Points)**\n",
        "\n",
        "**TO DO:** Fit the given decision tree to X_train and y_train data. You may use [this link](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.fit) for reference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLKCjKwJzofY"
      },
      "outputs": [],
      "source": [
        "model = RandomForestRegressor()\n",
        "\n",
        "##### INPUT CODE HERE (~1 line of code) ######\n",
        "\n",
        "##############################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvTNzrcr0j4x"
      },
      "source": [
        "**STEP 4: Try Predicting Values**\n",
        "\n",
        "**TO DO (optional) :** Change values of features to see changes in the predicted value of house"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rIm-v6ZH0Ju"
      },
      "outputs": [],
      "source": [
        "# this is an example test case depicting how the prediction is done on a test data point.\n",
        "\n",
        "val1 = 8.3252\n",
        "val2 = 41.0\n",
        "val3 = 6.984127\n",
        "val4 = 1.023810\n",
        "val5 = 322.0\n",
        "val6 = 2.555556\n",
        "val7 = 37.88\n",
        "val8 = -122.23\n",
        "\n",
        "row = [[val1, val2, val3, val4, val5, val6, val7, val8]]\n",
        "\n",
        "# make a single prediction\n",
        "yhat = model.predict(row)\n",
        "\n",
        "print('House Value Prediction= $',yhat[0]*100000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfzVPn0x437S"
      },
      "source": [
        "**STEP 5: Testing the model (4 Points)**\n",
        "\n",
        "**TO DO:** Find target predictions by giving **X_test** input to your model and store them in **y_pred**. You may need [this link](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.predict) for reference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHbnwEyt48Mr"
      },
      "outputs": [],
      "source": [
        "y_pred = None\n",
        "\n",
        "##### INPUT CODE HERE (~1 line of code) ######\n",
        "\n",
        "##############################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqGiMHYC5FFu"
      },
      "source": [
        "**STEP 6: Visualize the Results (4 Points)**\n",
        "\n",
        "**TO DO:** Since this is not a classification task, we cannot plot confusion matrix. Instead we ask you to find the mean square error evaluated on all the testing data and store it in **mse**.\n",
        "\n",
        "You may need the following reference:\n",
        "\n",
        "[Mean Square Error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sv-idAUX5Il-"
      },
      "outputs": [],
      "source": [
        "mse = None\n",
        "\n",
        "##### INPUT CODE HERE (~1 line of code) ######\n",
        "\n",
        "##############################################\n",
        "\n",
        "print(\"Mean Squared Error = \",mse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjrWJNii6Noe"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZ167Bw2d9wx"
      },
      "source": [
        "# **Hyperparameter Tuning: 5 Points**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKHA6-2_KTDh"
      },
      "source": [
        "**STEP 1: Hyperparameter Tuning (5 Points)**\n",
        "\n",
        "**TO DO:** Given the different range of the hyper parameters, tune them using grid search to get the value of these variables to get the best model is. Make sure the grid search is run for **5 rounds** of cross validation using **negative mean squared error**. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PZtUfovUgiQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHFVGQB1Uf_n"
      },
      "outputs": [],
      "source": [
        "param_grid = [\n",
        "    {'n_estimators': [10, 50, 100], 'max_features': [4, 5, 6 ], 'max_depth': [6, 7, 8, 9]}\n",
        "]\n",
        "\n",
        "#Use Random Forests\n",
        "forest_reg = RandomForestRegressor()\n",
        "\n",
        "##############################################\n",
        "# Write the code for hyperparameter tuning using Grid Search for the above parameters\n",
        "# Carry out the grid search and fit the data on the above variable -> \"grid_search\"\n",
        "\n",
        "##############################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKupJ2WmK180"
      },
      "outputs": [],
      "source": [
        "# Display the best parameter combination\n",
        "grid_search.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Retrain the Random Forest Regressor model and Plot Learning Curves: 20 Points**"
      ],
      "metadata": {
        "id": "5axY3Mvely9L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TODO:  Retrain the model using only the top 5 features (10 Points)**"
      ],
      "metadata": {
        "id": "eE45RFvZjwg9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get feature importances (2 points)\n",
        "##### INPUT CODE HERE (~1 line of code) ######\n",
        "\n",
        "##############################################\n",
        "\n",
        "# Sort feature importances in descending order and select top 5 (2 points)\n",
        "##### INPUT CODE HERE (~2 line of code) ######\n",
        "\n",
        "##############################################\n",
        "\n",
        "#print top 5 import features (2 points)\n",
        "print(\"Top 5 important features:\")\n",
        "##### INPUT CODE HERE (~2 line of code) ######\n",
        "\n",
        "##############################################\n",
        "\n",
        "# Retrain the model using only the top 5 features (4 points)\n",
        "##### INPUT CODE HERE (~2 line of code) ######\n",
        "\n",
        "##############################################\n",
        "\n",
        "model.fit(X_train_top_features, y_train)\n",
        "y_pred = model.predict(X_test_top_features)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "#You should obtain MSE less than 0.3\n",
        "print(\"Mean Squared Error after feature selection = \", mse)"
      ],
      "metadata": {
        "id": "zoO1A39jjuaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TODO:  Plot Learning Curve and Calculate Scores (10 Points)**"
      ],
      "metadata": {
        "id": "mve7Cd-al-s0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "# Get learning curves (3 points)\n",
        "##### INPUT CODE HERE (~2 line of code) ######\n",
        "\n",
        "##############################################\n",
        "\n",
        "# Calculate mean and standard deviation for training set scores (3 points)\n",
        "##### INPUT CODE HERE (~2 line of code) ######\n",
        "\n",
        "##############################################\n",
        "\n",
        "# Calculate mean and standard deviation for test set scores (4 points)\n",
        "##### INPUT CODE HERE (~2 line of code) ######\n",
        "\n",
        "##############################################\n",
        "\n",
        "# Plot learning curves\n",
        "plt.plot(train_sizes, train_mean, label=\"Training score\")\n",
        "plt.plot(train_sizes, test_mean, label=\"Cross-validation score\")\n",
        "\n",
        "# Draw bands\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\n",
        "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"#DDDDDD\")\n",
        "\n",
        "# Visualize : Create plot\n",
        "plt.title(\"Learning Curve\")\n",
        "plt.xlabel(\"Training Set Size\"), plt.ylabel(\"Accuracy Score\"), plt.legend(loc=\"best\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xZskX09Hl8g_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvDiveQuUVjX"
      },
      "source": [
        "# **FYI Only**\n",
        "# The below code is for you to learn more about Random Forest and will not be graded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aciYVvHl6SXc"
      },
      "source": [
        "This section is for your information only. Simply run the code cells one by one.\n",
        "\n",
        "We will take a closer look at some of the hyperparameters you should consider tuning for the random forest ensemble and their effect on model performance.\n",
        "\n",
        "We select the hyperparameters that give us the lowest error rate or Mean Square Error in this case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MORy4fvn6tLr"
      },
      "source": [
        "First we define a function to evaluate a model using the mean square error metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZMltehuec4q"
      },
      "outputs": [],
      "source": [
        "def find_mse(model, X, y):\n",
        "\n",
        "  yhat = model.predict(X)\n",
        "  mse = mean_squared_error(y,yhat) \n",
        "\n",
        "  return mse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U53kHMzd6-7l"
      },
      "source": [
        "Next we define a function to test out various models and plot how the Mean Square Error evolves with respect to the hyperparameter in question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttit1Xm4eqeP"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot\n",
        "\n",
        "def plot_tuning(models_dict,X_train,X_test,y_train,y_test):\n",
        "\n",
        "  results, names = list(), list()\n",
        "\n",
        "  for name, model in models_dict.items():\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    mse = find_mse(model, X_test, y_test)\n",
        "  \n",
        "    results.append(mse)\n",
        "    names.append(name)\n",
        "    print(\"Hyperparameter= \",name,\"; MSE = \",mse)\n",
        "\n",
        "\n",
        "    n = [float(i) for i in names]\n",
        "\n",
        "  pyplot.plot(n,results)\n",
        "  pyplot.ylabel('Mean Square Error')\n",
        "  pyplot.xlabel('Hyperparameter')\n",
        "  pyplot.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AbjOvTDeCGR"
      },
      "source": [
        "**Hyperparameter:** max_samples.\n",
        "\n",
        "The **max_samples** argument can be set to a float between 0 and 1 to control the percentage of the size of the training dataset to make the sample used to train each decision tree. **None** means that the entire training set will be used to train each tree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcEEhuLEYpZ1"
      },
      "outputs": [],
      "source": [
        "#Store various models into a dictionary of models\n",
        "models_dict = dict()\n",
        "for i in np.arange(0.1, 1.1, 0.1):\n",
        "  # set max_samples=None to use 100%\n",
        "  key = round(i,2)\n",
        "  if i == 1.0:\n",
        "    i = None\n",
        "  models_dict[key] = RandomForestRegressor(max_samples=i)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UkIwr82m4wF"
      },
      "outputs": [],
      "source": [
        "#Plot the MSE for all models in the dictionary\n",
        "plot_tuning(models_dict,X_train,X_test,y_train,y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1TOelFJ9jXx"
      },
      "source": [
        "**Hyperparameter:** max_features.\n",
        "\n",
        "The number of features that is randomly sampled for each split point is perhaps the most important feature to configure for random forest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1TOiDTDgL7h"
      },
      "outputs": [],
      "source": [
        "#Store various models into a dictionary of models\n",
        "models_dict = dict()\n",
        "\n",
        "for i in range(1,8):\n",
        "  models_dict[str(i)] = RandomForestRegressor(max_features=i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSgMQgIfne3Q"
      },
      "outputs": [],
      "source": [
        "#Plot the MSE for all models in the dictionary\n",
        "plot_tuning(models_dict,X_train,X_test,y_train,y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FEQHe7Y-Khh"
      },
      "source": [
        "**Hyperparameter:** n_estimators.\n",
        "\n",
        "Typically, the number of trees is increased until the model performance stabilizes. Intuition might suggest that more trees will lead to overfitting, although this is not the case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTblvr9xnh_0"
      },
      "outputs": [],
      "source": [
        "#Store various models into a dictionary of models\n",
        "models_dict = dict()\n",
        "\n",
        "n_trees = [10, 50, 100, 500, 1000]\n",
        "for n in n_trees:\n",
        "    models_dict[str(n)] = RandomForestRegressor(n_estimators=n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRLUXSYXoGeE"
      },
      "outputs": [],
      "source": [
        "#Plot the MSE for all models in the dictionary\n",
        "plot_tuning(models_dict,X_train,X_test,y_train,y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U50Q4-pUF1En"
      },
      "source": [
        "***"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}